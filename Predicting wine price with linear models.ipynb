{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data is from: https://www.kaggle.com/zynicide/wine-reviews. The data's scraped from WineEthusiast and was made available for use on Kaggle.\n",
    "\n",
    "Continuing on from before, let's try to see if we can predict the wine variety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>region_2</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>US</td>\n",
       "      <td>This tremendous 100% varietal wine hails from ...</td>\n",
       "      <td>Martha's Vineyard</td>\n",
       "      <td>96</td>\n",
       "      <td>235.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Napa Valley</td>\n",
       "      <td>Napa</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Heitz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Ripe aromas of fig, blackberry and cassis are ...</td>\n",
       "      <td>Carodorum Selección Especial Reserva</td>\n",
       "      <td>96</td>\n",
       "      <td>110.0</td>\n",
       "      <td>Northern Spain</td>\n",
       "      <td>Toro</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Tinta de Toro</td>\n",
       "      <td>Bodega Carmen Rodríguez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>US</td>\n",
       "      <td>Mac Watson honors the memory of a wine once ma...</td>\n",
       "      <td>Special Selected Late Harvest</td>\n",
       "      <td>96</td>\n",
       "      <td>90.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Knights Valley</td>\n",
       "      <td>Sonoma</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Macauley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>US</td>\n",
       "      <td>This spent 20 months in 30% new French oak, an...</td>\n",
       "      <td>Reserve</td>\n",
       "      <td>96</td>\n",
       "      <td>65.0</td>\n",
       "      <td>Oregon</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Willamette Valley</td>\n",
       "      <td>Pinot Noir</td>\n",
       "      <td>Ponzi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>France</td>\n",
       "      <td>This is the top wine from La Bégude, named aft...</td>\n",
       "      <td>La Brûlade</td>\n",
       "      <td>95</td>\n",
       "      <td>66.0</td>\n",
       "      <td>Provence</td>\n",
       "      <td>Bandol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Provence red blend</td>\n",
       "      <td>Domaine de la Bégude</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 country                                        description  \\\n",
       "0           0      US  This tremendous 100% varietal wine hails from ...   \n",
       "1           1   Spain  Ripe aromas of fig, blackberry and cassis are ...   \n",
       "2           2      US  Mac Watson honors the memory of a wine once ma...   \n",
       "3           3      US  This spent 20 months in 30% new French oak, an...   \n",
       "4           4  France  This is the top wine from La Bégude, named aft...   \n",
       "\n",
       "                            designation  points  price        province  \\\n",
       "0                     Martha's Vineyard      96  235.0      California   \n",
       "1  Carodorum Selección Especial Reserva      96  110.0  Northern Spain   \n",
       "2         Special Selected Late Harvest      96   90.0      California   \n",
       "3                               Reserve      96   65.0          Oregon   \n",
       "4                            La Brûlade      95   66.0        Provence   \n",
       "\n",
       "            region_1           region_2             variety  \\\n",
       "0        Napa Valley               Napa  Cabernet Sauvignon   \n",
       "1               Toro                NaN       Tinta de Toro   \n",
       "2     Knights Valley             Sonoma     Sauvignon Blanc   \n",
       "3  Willamette Valley  Willamette Valley          Pinot Noir   \n",
       "4             Bandol                NaN  Provence red blend   \n",
       "\n",
       "                    winery  \n",
       "0                    Heitz  \n",
       "1  Bodega Carmen Rodríguez  \n",
       "2                 Macauley  \n",
       "3                    Ponzi  \n",
       "4     Domaine de la Bégude  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"winemag-data_first150k.csv\"\n",
    "path = \"C:/Data/Projects/Wine/\"\n",
    "data = pd.read_csv(path + filename)\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150930.000000</td>\n",
       "      <td>150930.000000</td>\n",
       "      <td>137235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>75464.500000</td>\n",
       "      <td>87.888418</td>\n",
       "      <td>33.131482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>43569.882402</td>\n",
       "      <td>3.222392</td>\n",
       "      <td>36.322536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>37732.250000</td>\n",
       "      <td>86.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>75464.500000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>113196.750000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>40.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>150929.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Unnamed: 0         points          price\n",
       "count  150930.000000  150930.000000  137235.000000\n",
       "mean    75464.500000      87.888418      33.131482\n",
       "std     43569.882402       3.222392      36.322536\n",
       "min         0.000000      80.000000       4.000000\n",
       "25%     37732.250000      86.000000      16.000000\n",
       "50%     75464.500000      88.000000      24.000000\n",
       "75%    113196.750000      90.000000      40.000000\n",
       "max    150929.000000     100.000000    2300.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can immediately see a few things- the cheapest wine is 4 dollars, while the most expensive is 2300 dollars, with the mean price being 33. In terms of points, the worst wine comes in a 80 points, while the best comes in at 100. Even at 80 points I'd say that's pretty high- people like their wine!\n",
    "\n",
    "# Cleaning #\n",
    "\n",
    "Let's clean the data. First, let's check if there are any null values in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns with null values:\n",
      " Unnamed: 0         0\n",
      "country            5\n",
      "description        0\n",
      "designation    45735\n",
      "points             0\n",
      "price          13695\n",
      "province           5\n",
      "region_1       25060\n",
      "region_2       89977\n",
      "variety            0\n",
      "winery             0\n",
      "dtype: int64\n",
      "Number of observations:\n",
      " 150930\n"
     ]
    }
   ],
   "source": [
    "are_null_values = data.isnull().values.any()\n",
    "num_nulls = data.isnull().sum()\n",
    "print(\"Columns with null values:\\n\",num_nulls)\n",
    "print(\"Number of observations:\\n\",len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 45735 null values for designation, 13695 for price, 25060 for region_1, and 89977 for region_2. That means only about 40% of the data has a region_2 value- I don't want to drop all null values then, or else I'll be getting rid of 60% of my data. I don't think region_2 is that important, since we already have the country, province, and region_1. I'll go ahead and just drop region_2 from the dataframe. Then I'll drop rows that have null values- this will result in losing less data. Let's also drop \"Unnamed: 0\" since this is just a duplication of the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150930, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(\"region_2\", axis = 1)\n",
    "data = data[pd.notnull(data)] # drop if null values\n",
    "data = data.drop(\"Unnamed: 0\", axis = 1) # drop the first column\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we want to make sure that every description is unique. Some descriptions may be duplicated, which means a wine has been entered in the dataset twice. Let's ensure that every description appears only once, but first let's check to see if there are duplicates, then drop them accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>147725</th>\n",
       "      <td>Chile</td>\n",
       "      <td>$11. Opens with a highly perfumed bouquet of l...</td>\n",
       "      <td>Estate Reserve</td>\n",
       "      <td>84</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Maipo Valley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>La Playa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62345</th>\n",
       "      <td>Chile</td>\n",
       "      <td>$11. Opens with a highly perfumed bouquet of l...</td>\n",
       "      <td>Estate Reserve</td>\n",
       "      <td>84</td>\n",
       "      <td>11.0</td>\n",
       "      <td>Maipo Valley</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>La Playa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74993</th>\n",
       "      <td>US</td>\n",
       "      <td>). Very good wine from a winery increasingly k...</td>\n",
       "      <td>Rockpile Ridge Vineyard</td>\n",
       "      <td>92</td>\n",
       "      <td>47.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Rockpile</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Mauritson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18803</th>\n",
       "      <td>US</td>\n",
       "      <td>). Very good wine from a winery increasingly k...</td>\n",
       "      <td>Rockpile Ridge Vineyard</td>\n",
       "      <td>92</td>\n",
       "      <td>47.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Rockpile</td>\n",
       "      <td>Cabernet Sauvignon</td>\n",
       "      <td>Mauritson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26530</th>\n",
       "      <td>Austria</td>\n",
       "      <td>. Christoph Neumeister's top wine, this is a c...</td>\n",
       "      <td>Moarfeitl</td>\n",
       "      <td>93</td>\n",
       "      <td>48.0</td>\n",
       "      <td>Südoststeiermark</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Neumeister</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        country                                        description  \\\n",
       "147725    Chile  $11. Opens with a highly perfumed bouquet of l...   \n",
       "62345     Chile  $11. Opens with a highly perfumed bouquet of l...   \n",
       "74993        US  ). Very good wine from a winery increasingly k...   \n",
       "18803        US  ). Very good wine from a winery increasingly k...   \n",
       "26530   Austria  . Christoph Neumeister's top wine, this is a c...   \n",
       "\n",
       "                    designation  points  price          province  region_1  \\\n",
       "147725           Estate Reserve      84   11.0      Maipo Valley       NaN   \n",
       "62345            Estate Reserve      84   11.0      Maipo Valley       NaN   \n",
       "74993   Rockpile Ridge Vineyard      92   47.0        California  Rockpile   \n",
       "18803   Rockpile Ridge Vineyard      92   47.0        California  Rockpile   \n",
       "26530                 Moarfeitl      93   48.0  Südoststeiermark       NaN   \n",
       "\n",
       "                   variety      winery  \n",
       "147725          Chardonnay    La Playa  \n",
       "62345           Chardonnay    La Playa  \n",
       "74993   Cabernet Sauvignon   Mauritson  \n",
       "18803   Cabernet Sauvignon   Mauritson  \n",
       "26530      Sauvignon Blanc  Neumeister  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated('description', keep = False)].sort_values('description').head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89108, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop_duplicates(\"description\") # drop duplicate descriptions\n",
    "data[\"designation\"] = data[\"designation\"].str.lower() # make sure all lower\n",
    "data = data[pd.notnull(data)] # drop null values\n",
    "data = data[data.price.notnull()] # ensure the price and points rows that are null are dropped\n",
    "ata = data[data.points.notnull()]\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to ensure that the variety name doesn't occur in the description, so let's add variety name to our list of stop words to remove from the description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agiorgitiko', 'aglianico', 'aidani', 'airen', 'albana']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variety_words = set()\n",
    "for wine_variety in data.variety:\n",
    "    wine_variety = wine_variety.lower()\n",
    "    wine_variety = wine_variety.split()\n",
    "    for word in wine_variety:\n",
    "        variety_words.add(word)\n",
    "\n",
    "variety_list = sorted(variety_words)\n",
    "variety_list[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Remove stop words\n",
    "# Set the stop words\n",
    "from nltk.corpus import stopwords\n",
    "extras = ['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}', 'cab',\"%\", \"that's\"]\n",
    "stopwords = set(stopwords.words('english'))\n",
    "stopwords.update(variety_list)\n",
    "stopwords.update(extras)\n",
    "# Now remove the stop words\n",
    "data[\"description\"] = data[\"description\"].apply(lambda x: x.lower())    \n",
    "data[\"description\"] = data[\"description\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>description</th>\n",
       "      <th>designation</th>\n",
       "      <th>points</th>\n",
       "      <th>price</th>\n",
       "      <th>province</th>\n",
       "      <th>region_1</th>\n",
       "      <th>variety</th>\n",
       "      <th>winery</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>149634</th>\n",
       "      <td>France</td>\n",
       "      <td>atypically light body reticent nose, gewürz in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>15.0</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Alsace</td>\n",
       "      <td>Gewürztraminer</td>\n",
       "      <td>W. Gisselbrecht</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149635</th>\n",
       "      <td>US</td>\n",
       "      <td>dry rustically tannic, gritty, chewy feeling, ...</td>\n",
       "      <td>bungalow red</td>\n",
       "      <td>84</td>\n",
       "      <td>15.0</td>\n",
       "      <td>California</td>\n",
       "      <td>Santa Barbara County</td>\n",
       "      <td>Syrah-Grenache</td>\n",
       "      <td>Casa Barranca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149637</th>\n",
       "      <td>US</td>\n",
       "      <td>outside vineyard, wines like built company's p...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>6.0</td>\n",
       "      <td>California</td>\n",
       "      <td>California</td>\n",
       "      <td>Merlot</td>\n",
       "      <td>Delicato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149638</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>heavy basic, pineapple aromas. full-flavored t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Mendoza Province</td>\n",
       "      <td>Uco Valley</td>\n",
       "      <td>Sauvignon Blanc</td>\n",
       "      <td>Finca El Portillo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149639</th>\n",
       "      <td>Australia</td>\n",
       "      <td>smooth mouth, chard starts citrus dust aromas ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>84</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Australia Other</td>\n",
       "      <td>South Eastern Australia</td>\n",
       "      <td>Chardonnay</td>\n",
       "      <td>Jacob's Creek</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country                                        description  \\\n",
       "149634     France  atypically light body reticent nose, gewürz in...   \n",
       "149635         US  dry rustically tannic, gritty, chewy feeling, ...   \n",
       "149637         US  outside vineyard, wines like built company's p...   \n",
       "149638  Argentina  heavy basic, pineapple aromas. full-flavored t...   \n",
       "149639  Australia  smooth mouth, chard starts citrus dust aromas ...   \n",
       "\n",
       "         designation  points  price          province  \\\n",
       "149634           NaN      84   15.0            Alsace   \n",
       "149635  bungalow red      84   15.0        California   \n",
       "149637           NaN      84    6.0        California   \n",
       "149638           NaN      84    9.0  Mendoza Province   \n",
       "149639           NaN      84    8.0   Australia Other   \n",
       "\n",
       "                       region_1          variety             winery  \n",
       "149634                   Alsace   Gewürztraminer    W. Gisselbrecht  \n",
       "149635     Santa Barbara County   Syrah-Grenache      Casa Barranca  \n",
       "149637               California           Merlot           Delicato  \n",
       "149638               Uco Valley  Sauvignon Blanc  Finca El Portillo  \n",
       "149639  South Eastern Australia       Chardonnay      Jacob's Creek  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Let's see if we can determine a wine's price. To start, let's work with the province, description, points, and variety. I won't include country since province includes country. To keep the feature set managebale, I'll exclude region_1, designation, and winery.\n",
    "\n",
    "So our features are: Description, points, province, variety.\n",
    "\n",
    "Let's first do our imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use TfidfVectorizor to process the wine descriptions to get Tfidf features. We'll use several linear models: linear regression, ridge regression, lasso, and PCA regression. As it's often useful to standardize variables with linear models, we'll try this too. Our only numerical values really are from the points column, the rest are one hot vectors (from variety and winery), and the Tfidf features as mentioned for the wine descriptions. Our error metrics will be mean square error (the smaller the better), and explained variance score (the closer to 1.0 the better). \n",
    "\n",
    "Let's prep the data for our linear models. There's a decent amount of outliers in the data so let's be weary of that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prep_data(data, outlier_threshold, remove_outliers = True):\n",
    "    if remove_outliers:\n",
    "        data = data[data.price < outlier_threshold]\n",
    "    else:\n",
    "        data = data\n",
    "    X = data.drop(['country','designation','region_1','winery', 'price'], axis = 1)\n",
    "    y = data.price.astype(float)\n",
    "    # Tokenize our description before splitting\n",
    "    tfidf = TfidfVectorizer(min_df = 977) # Ignore terms that appear in less than 1% of samples. this reduces the feature space\n",
    "    descrip = tfidf.fit_transform(X.description).toarray()\n",
    "    # One hot encode the provinces and varieties\n",
    "    provinces = pd.get_dummies(X.province)\n",
    "    varieties = pd.get_dummies(X.variety)\n",
    "    # Stack the matrices\n",
    "    points_ = X.points.values\n",
    "    X = np.hstack((descrip, provinces, varieties, points_[:,None]))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to do some modelling! Let's write some helper functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def try_linear_models(X_, y_, model_name, standardize = True):\n",
    "    if standardize == True:\n",
    "        X = preprocessing.scale(X_)\n",
    "    else:\n",
    "        X = X_\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y_, random_state = 42)\n",
    "    if model_name == \"linear\":\n",
    "        model = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "    if model_name == \"ridge\":\n",
    "        model = linear_model.Ridge(alpha = 0.1).fit(X_train, y_train)\n",
    "    if model_name == \"lasso\":\n",
    "        model = linear_model.Lasso(alpha = 0.5).fit(X_train, y_train)\n",
    "    if model_name == \"pca_reg\":\n",
    "        n_components = 16\n",
    "        pca = PCA(n_components,svd_solver='randomized',whiten=True).fit(X)\n",
    "        data = pca.transform(X)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data, y_, random_state = 42)\n",
    "        model = linear_model.LinearRegression().fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    return predictions, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_metrics(model, predictions, y_test):\n",
    "    print(\"Model: \", model)\n",
    "    # The mean squared error\n",
    "    print(\"--Mean squared error: %.2f\" % mean_squared_error(y_test, predictions))\n",
    "    # Explained variance score: 1 is perfect prediction\n",
    "    print('--Variance score: %.2f' % r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Take a look at some of the results\n",
    "def inspect_df(predictions, y_test):\n",
    "    true_vs_pred = np.vstack((predictions, y_test))\n",
    "    true_df = pd.DataFrame(true_vs_pred)\n",
    "    true_df = true_df.transpose()\n",
    "    true_df.columns = [\"Predicted\", \"Actual\"]\n",
    "    return true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display_html\n",
    "def display_side_by_side(*args):\n",
    "    html_str=''\n",
    "    for df in args:\n",
    "        html_str+=df.to_html()\n",
    "    display_html(html_str.replace('table','table style=\"display:inline\"'),raw=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done, *now* we can do some fun stuff!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Ridge with standardizing\n",
      "--Mean squared error: 1015.94\n",
      "--Variance score: 0.31\n",
      "Model:  Lasso with standardizing\n",
      "--Mean squared error: 1045.60\n",
      "--Variance score: 0.29\n",
      "Model:  PCA regression with standardizing\n",
      "--Mean squared error: 1190.58\n",
      "--Variance score: 0.19\n",
      "Model:  Ridge without standardizing\n",
      "--Mean squared error: 1015.03\n",
      "--Variance score: 0.31\n",
      "Model:  Lasso without standardizing\n",
      "--Mean squared error: 1156.22\n",
      "--Variance score: 0.21\n",
      "Model:  PCA regression without standardizing\n",
      "--Mean squared error: 1132.06\n",
      "--Variance score: 0.23\n"
     ]
    }
   ],
   "source": [
    "# Get model results\n",
    "# Without removing any outliers\n",
    "X, y = prep_data(data, outlier_threshold = 0, remove_outliers = False)\n",
    "\n",
    "# With standardizing\n",
    "ridge_pred_st, y_test = try_linear_models(X, y, \"ridge\", standardize=True)\n",
    "lasso_pred_st, y_test = try_linear_models(X, y, \"lasso\", standardize=True)\n",
    "pca_pred_st, y_test = try_linear_models(X, y, \"pca_reg\", standardize=True)\n",
    "\n",
    "# Without standardizing\n",
    "ridge_pred, y_test = try_linear_models(X, y, \"ridge\", standardize=False)\n",
    "lasso_pred, y_test = try_linear_models(X, y, \"lasso\", standardize=False)\n",
    "pca_pred, y_test = try_linear_models(X, y, \"pca_reg\", standardize=False)\n",
    "\n",
    "# Error metrics\n",
    "error_metrics(\"Ridge with standardizing\", ridge_pred_st, y_test)\n",
    "error_metrics(\"Lasso with standardizing\", lasso_pred_st, y_test)\n",
    "error_metrics(\"PCA regression with standardizing\", pca_pred_st, y_test)\n",
    "\n",
    "error_metrics(\"Ridge without standardizing\", ridge_pred, y_test)\n",
    "error_metrics(\"Lasso without standardizing\", lasso_pred, y_test)\n",
    "error_metrics(\"PCA regression without standardizing\", pca_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like ridge regression does the best, both with standardized and non standardized variables. Let's take a quick look at what some of our predictions actually look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22267</th>\n",
       "      <td>20.093576</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22268</th>\n",
       "      <td>5.655745</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22269</th>\n",
       "      <td>23.180856</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22270</th>\n",
       "      <td>13.199893</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22271</th>\n",
       "      <td>101.267411</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22272</th>\n",
       "      <td>-3.431131</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273</th>\n",
       "      <td>29.570737</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22274</th>\n",
       "      <td>35.777497</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22275</th>\n",
       "      <td>75.795340</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22276</th>\n",
       "      <td>54.749942</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\"><table style=\"display:inline\" border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22267</th>\n",
       "      <td>20.070574</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22268</th>\n",
       "      <td>5.695289</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22269</th>\n",
       "      <td>23.205269</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22270</th>\n",
       "      <td>13.186430</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22271</th>\n",
       "      <td>101.262748</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22272</th>\n",
       "      <td>-3.411859</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22273</th>\n",
       "      <td>29.576133</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22274</th>\n",
       "      <td>35.767893</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22275</th>\n",
       "      <td>75.803441</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22276</th>\n",
       "      <td>54.746645</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table style=\"display:inline\">"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at ridge regression with standardized variables, and without\n",
    "# LEFT: With standardized variables\n",
    "# RIGHT: Without\n",
    "display_side_by_side(inspect_df(ridge_pred_st, y_test).tail(10),inspect_df(ridge_pred, y_test).tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So you can see that our ridge regression for some labels is quite good, but for some is way off! Actually, there are some pretty expensive wines in the dataset. In fact, 99.99 % of the data comes in below 1000 dollars. So let's see how the model performs when we remove these more expensive wines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  Ridge with standardizing\n",
      "--Mean squared error: 748.77\n",
      "--Variance score: 0.36\n",
      "Model:  Lasso with standardizing\n",
      "--Mean squared error: 778.95\n",
      "--Variance score: 0.33\n",
      "Model:  PCA regression with standardizing\n",
      "--Mean squared error: 902.73\n",
      "--Variance score: 0.22\n",
      "Model:  Ridge without standardizing\n",
      "--Mean squared error: 748.38\n",
      "--Variance score: 0.36\n",
      "Model:  Lasso without standardizing\n",
      "--Mean squared error: 879.00\n",
      "--Variance score: 0.24\n",
      "Model:  PCA regression without standardizing\n",
      "--Mean squared error: 857.97\n",
      "--Variance score: 0.26\n"
     ]
    }
   ],
   "source": [
    "# Get model results\n",
    "# Remove bottles that cost more than 1000 dollars\n",
    "X, y = prep_data(data, outlier_threshold = 1000.0, remove_outliers = True)\n",
    "# With standardizing\n",
    "ridge_pred_st, y_test = try_linear_models(X, y, \"ridge\", standardize=True)\n",
    "lasso_pred_st, y_test = try_linear_models(X, y, \"lasso\", standardize=True)\n",
    "pca_pred_st, y_test = try_linear_models(X, y, \"pca_reg\", standardize=True)\n",
    "# Without standardizing\n",
    "ridge_pred, y_test = try_linear_models(X, y, \"ridge\", standardize=False)\n",
    "lasso_pred, y_test = try_linear_models(X, y, \"lasso\", standardize=False)\n",
    "pca_pred, y_test = try_linear_models(X, y, \"pca_reg\", standardize=False)\n",
    "\n",
    "# Error metrics\n",
    "error_metrics(\"Ridge with standardizing\", ridge_pred_st, y_test)\n",
    "error_metrics(\"Lasso with standardizing\", lasso_pred_st, y_test)\n",
    "error_metrics(\"PCA regression with standardizing\", pca_pred_st, y_test)\n",
    "error_metrics(\"Ridge without standardizing\", ridge_pred, y_test)\n",
    "error_metrics(\"Lasso without standardizing\", lasso_pred, y_test)\n",
    "error_metrics(\"PCA regression without standardizing\", pca_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression still seems to come out on top. Let's take a look at the residual plot. Ideally the residuals will be random about the horizontal line at zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1000.,  -800.,  -600.,  -400.,  -200.,     0.,   200.]),\n",
       " <a list of 7 Text yticklabel objects>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAEYCAYAAADmugmLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x201aaa256d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(ridge_pred_st, ridge_pred_st - y_test)\n",
    "plt.hlines(y= 0, xmin = min(ridge_pred_st), xmax = max(ridge_pred_st))\n",
    "plt.ylabel(\"Residuals\", fontsize = 20)\n",
    "plt.xlabel(\"Predicted\", fontsize = 20)\n",
    "plt.xticks(fontsize = 15)\n",
    "plt.yticks(fontsize = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We definitely see some heteroskedasticity going on here. That's not good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Overall, how did we do? Honestly, not the best. The fact that the residuals show heteroskedasticity for our \"best\" result with ridge regression shows that there's something going on in the data that the linear models have failed to capture. This means there could be feature engineering that needs to be done, such as transformations, or we need some new predictors. \n",
    "##### Data to add\n",
    "Useful data to add could be the wine's vintage (although I think it wouldn't be too hard to go out and fetch that manually), as well as the sentiment of the description- although I suppose that would be all neutral or positive, but still, it could have an effect on the price. \n",
    "##### Limitations\n",
    "Another thing to consider could be a model for each range of wine- i.e., a wine connoisseur could tell me what price ranges are typical for wines, since I'm not an expert. And that brings up another limitation. I don't know that much about wine, and I'm not even 100% sure what one of the features in the data set, designation, means. As a result, I left it out of the linear models.\n",
    "##### Standardizing\n",
    "It's interesting to me that standardizing doesn't have much of an effect, but this makes sense because only points are integer values, the rest of the features are either Tfidf features or one hot vectors. Lasso even did worse with scaling. Furthermore, when you scale data you assume the data are on different scales to start with. Of course if there's only one quantitative variable then it will be on the same scale as itself!\n",
    "##### The business side\n",
    "Now another question I always like to think about: Why even do this? How can you make money from predicting wine prices? A winery can't change where it's located, all it can change is its description and the points its wine receives. Points is a bit out of their control too, since wine critics are the ones that assign this value. So this comes down to description. An idea could be to look into the relationship between description and price, and get into the text analytics of it. If we can identify certain words or characteristics of a description associated with expensive wine, then a winery could price its wine accordingly (aka, make it more expensive!) and then make money from this."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
